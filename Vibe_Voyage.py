# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AsInga4TQLvH7zgxsr8I7H8Nw3JfQJou
"""

# --- INSTALLATION CELL ---
!pip install pyspark==3.5.0 spotipy pandas requests python-dotenv
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.42.0.0/sqlite-jdbc-3.42.0.0.jar -O /content/sqlite-jdbc-3.42.0.0.jar
print("Dependencies installed and SQLite JDBC driver downloaded.")



# --- INITIALIZATION CELL ---
import os
from pyspark.sql import SparkSession
from pyspark.sql.types import *
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import requests
import json
import pandas as pd
import sqlite3

# 1. SPARK SESSION SETUP
# The 'spark.jars' configuration adds the SQLite JDBC driver to the Spark classpath
# so PySpark can communicate with the SQLite file.
SPARK_JDBC_PATH = "/content/sqlite-jdbc-3.42.0.0.jar"
spark = (SparkSession
    .builder
    .appName("VibeVoyageProofOfConcept")
    .config("spark.jars", SPARK_JDBC_PATH)
    .getOrCreate()
)
print("PySpark Session Initialized.")

# 2. API CREDENTIALS (REPLACE WITH YOUR KEYS!)
SPOTIPY_CLIENT_ID ="2f5ae45eb1aa49178229bb036a6183f7"
SPOTIPY_CLIENT_SECRET ="d3dfb249652c4d24abc9319b87e6bc48"

# 3. SPOTIFY CLIENT SETUP (Client Credentials Flow)
auth_manager = SpotifyClientCredentials(
    client_id=SPOTIPY_CLIENT_ID,
    client_secret=SPOTIPY_CLIENT_SECRET
)
sp = spotipy.Spotify(auth_manager=auth_manager)
print("Spotify Client Initialized.")

# --- UPDATED SPOTIFY FUNCTION CELL ---

def get_spotify_vibe_metrics_workaround(song_name, artist_name):
    """
    Searches for a track and gets its popularity and the Artist's Genres.
    """
    global sp # Ensure the global spotipy client is used
    try:
        query = f"track:{song_name} artist:{artist_name}"
        # 1. Search for the track
        results = sp.search(q=query, limit=1, type='track')
        tracks = results.get('tracks', {}).get('items', [])

        if not tracks:
            print(f"  [Spotify] No track found for '{song_name}' by '{artist_name}'.")
            return None

        track = tracks[0]
        track_name = track['name']
        artist_id = track['artists'][0]['id']

        # 2. Get the Artist's Genres (Requires a separate API call which is usually permitted)
        artist_info = sp.artist(artist_id)

        vibe_data = {
            "track_name": track_name,
            "artist_name": artist_name,
            "track_popularity": track['popularity'], # Score from 0-100
            "artist_genres": artist_info.get('genres', []) # List of genres
        }
        print(f"  [Spotify] Success! Fetched track and genre data for '{track_name}'.")
        return vibe_data

    except Exception as e:
        print(f"  [Spotify] Error during API call: {e}")
        # A 404 on the artist endpoint might mean the artist is a new/obscure one, return what we have
        return None

# DEMO: Fetch data using the new workaround
spotify_data = get_spotify_vibe_metrics_workaround("Mr. Brightside", "The Killers")
print(json.dumps(spotify_data, indent=2) if spotify_data else "Spotify Demo Failed.")



# --- 1. INSTALL AND IMPORT LIBRARIES ---

!pip install polars scikit-learn spotipy
import pandas as pd
import polars as pl # For fast loading of the 114k dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# Keep the necessary Spotify and data manipulation imports
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import numpy as np
# We don't need spark.sql.functions imports anymore

# --- 2. DEFINE VIBE CATEGORIES AND MAPPING ---

# The 4 Vibe Categories
VIBE_CATEGORIES = ['Introspective', 'Mellow', 'Intense', 'Jubilant']

# Create a manual mapping for training the ML model
# This maps the categories to numerical labels (0 to 3) for Scikit-learn
# LabelEncoder will automate this later, but defining it is good practice.
VIBE_MAPPING = {
    'Introspective': 0,
    'Mellow': 1,
    'Intense': 2,
    'Jubilant': 3
}

# The audio features we will use to train the Vibe Predictor
AUDIO_FEATURES = [
    'danceability', 'energy', 'speechiness', 'acousticness',
    'instrumentalness', 'liveness', 'valence', 'tempo', 'loudness', 'popularity'
]

# --- 3. LOAD THE SPOTIFY BACKUP DATASET (114k Tracks) ---

# Replace 'spotify_tracks_114k.csv' with the actual file name of your 114k track dataset
FILE_PATH = '/content/dataset.csv'

# Use Polars to load quickly, then convert to Pandas for Scikit-learn compatibility
try:
    # Polars loads the data much faster than Pandas for large CSVs
    spotify_backup_pl = pl.read_csv(FILE_PATH)

    # Convert to Pandas for compatibility with Scikit-learn
    spotify_backup_df = spotify_backup_pl.to_pandas()

    # Clean up the Polars DataFrame to save memory
    del spotify_backup_pl

    print(f"Loaded {len(spotify_backup_df):,} tracks from backup dataset.")

except FileNotFoundError:
    print(f"ERROR: Please upload the {FILE_PATH} file to your Colab environment.")
    spotify_backup_df = None

# --- 4. DATA CLEANING AND VIBE LABELING (Creating the Target Variable) ---

if spotify_backup_df is not None:
    # Drop rows with any missing values we need
    spotify_backup_df.dropna(subset=['track_genre', 'popularity', 'energy', 'valence'], inplace=True)

    # Recreate the GENRE_SCORE_MAP globally (or load it from a config file if available)
    GENRE_SCORE_MAP = {
        'bollywood': 0.90, 'hindi pop': 0.85, 'desi pop': 0.82, 'filmi': 0.70,
        'funk': 0.8, 'rock': 0.65, 'metal': 0.7, 'jazz': 0.45, 'classical': 0.2,
        # Add more genres as needed...
    }

    # Function to calculate Vibe Score using the heuristic model
    def calculate_vibe_score_series(genres_str, popularity):
        # Find the highest genre score in the list of genres
        genre_list = [g.strip() for g in genres_str.split(';')] if isinstance(genres_str, str) else [genres_str]

        # Calculate the base score, defaulting to 0 if no genre is found
        genre_base_score = max(GENRE_SCORE_MAP.get(g, 0) for g in genre_list)

        # Apply the 70/30 weighted formula
        vibe_score = (genre_base_score * 0.7) + ((popularity / 100.0) * 0.3)
        return vibe_score

    # Apply the Vibe Score calculation across the entire DataFrame
    spotify_backup_df['vibe_score'] = spotify_backup_df.apply(
        lambda row: calculate_vibe_score_series(row['track_genre'], row['popularity']),
        axis=1
    )

    # Assign Vibe Category based on the score (This creates the ML Target Label)
    def assign_vibe_category(score):
        if score >= 0.75:
            return 'Jubilant'
        elif score >= 0.50:
            return 'Intense'
        elif score >= 0.25:
            return 'Mellow'
        else:
            return 'Introspective'

    spotify_backup_df['vibe_category'] = spotify_backup_df['vibe_score'].apply(assign_vibe_category)

    print("Successfully labeled all backup tracks with Vibe Category for ML training.")

# --- 5. TRAIN THE K-NEAREST NEIGHBORS (KNN) CLASSIFIER ---

if spotify_backup_df is not None:

    # 1. Select Features (X) and Target (y)
    X = spotify_backup_df[AUDIO_FEATURES]
    y = spotify_backup_df['vibe_category']

    # 2. Encode the Target Variable (Vibe Category strings to numbers)
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)

    # 3. Split Data
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

    # 4. Standardize/Scale Features (Crucial for KNN and many ML models)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 5. Train the Model (Using KNN as a simple, effective multi-class classifier)
    # The number of neighbors (k=5) is a hyperparameter you can tune.
    vibe_model = KNeighborsClassifier(n_neighbors=5)
    vibe_model.fit(X_train_scaled, y_train)

    # 6. Evaluate Model Performance
    y_pred = vibe_model.predict(X_test_scaled)
    print("\n--- ML Model Training Complete ---")
    print("Classification Report:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    print("\n‚úÖ Vibe Predictor Model (KNN) is trained and ready!")

# --- 6. ML-BASED VIBE CALCULATION FUNCTION (New Core Logic) ---

def get_ml_vibe_category(api_data, vibe_model, scaler, label_encoder, audio_features):
    """
    Uses the trained Scikit-learn model to predict the Vibe Category
    based on the audio features retrieved from the Spotify API.

    Args:
        api_data (dict): Result from the Spotify API (must contain audio features).
        vibe_model (KNeighborsClassifier): The trained Scikit-learn KNN model.
        scaler (StandardScaler): The fitted StandardScaler object.
        label_encoder (LabelEncoder): The fitted LabelEncoder for Vibe Categories.
        audio_features (list): List of feature names used during training.

    Returns:
        str: The predicted Vibe Category (e.g., 'Jubilant').
    """

    # 1. Extract Features from API Data
    # NOTE: The Spotify API gives us features like danceability, energy, etc.
    # We use popularity from the track data since the API features lack it.

    # Create an input array matching the order of AUDIO_FEATURES used during training
    input_data = [api_data.get(feature, 0) for feature in audio_features]

    # Convert to a NumPy array and reshape for the scaler (required for single sample)
    X_input = np.array(input_data).reshape(1, -1)

    # 2. Scale the Input Data (MUST use the same scaler object used for training)
    X_scaled = scaler.transform(X_input)

    # 3. Predict the Vibe (Returns a numerical label, e.g., [3])
    y_pred_encoded = vibe_model.predict(X_scaled)[0]

    # 4. Decode the Label (Convert number back to category string, e.g., 'Jubilant')
    predicted_vibe = label_encoder.inverse_transform([y_pred_encoded])[0]

    # NOTE: The ML model predicts the category directly, so we don't calculate a raw score (0-1.0)
    # in the same way. We'll simply report the category.

    return predicted_vibe

print("‚úÖ ML Vibe Calculation function defined.")

# --- FIX: REDEFINE THE API WORKAROUND FUNCTION ---
# You need to ensure you have initialized spotipy and defined your Client ID/Secret
# in an earlier setup cell before running this.
# (E.g., sp = spotipy.Spotify(auth_manager=...))

def get_spotify_vibe_metrics_workaround(track_name, artist_name):
    # ... (function details) ...
    sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(
        client_id="2f5ae45eb1aa49178229bb036a6183f7",
        client_secret="d3dfb249652c4d24abc9319b87e6bc48"
    ))
    # ... (rest of the function) ...

    try:
        # 1. Search for the track
        results = sp.search(q=f'track:{track_name} artist:{artist_name}', type='track', limit=1)
        if not results['tracks']['items']:
            print(f"[{track_name}] Track not found on Spotify.")
            return None

        track = results['tracks']['items'][0]
        track_id = track['id']
        artist_id = track['artists'][0]['id']

        # 2. Get Audio Features (Needed for ML Model Input)
        audio_features = sp.audio_features([track_id])[0]

        # 3. Get Artist Genres (Needed for backup/logging)
        artist_genres = sp.artist(artist_id)['genres']

        # 4. Consolidate Data
        vibe_data = {
            'track_id': track_id,
            'track_name': track['name'],
            'artist_name': track['artists'][0]['name'],
            'popularity': track['popularity']
        }

        # Merge audio features into the main dictionary
        if audio_features:
            vibe_data.update(audio_features)

        # The ML model needs all features, including popularity, in the input vector.
        # We manually add genres for logging/fallback, even if the ML model doesn't use them directly.
        vibe_data['artist_genres'] = artist_genres

        print(f"  [Spotify] Success! Fetched track and features for '{track_name}'.")
        return vibe_data

    except Exception as e:
        print(f"  [API CALL ERROR] Failed to fetch data: {e}")
        return None

# NOTE: REMEMBER TO REPLACE "YOUR_CLIENT_ID" AND "YOUR_CLIENT_SECRET"
# with the actual values from the image you uploaded!
print("‚úÖ API function `get_spotify_vibe_metrics_workaround` is now defined.")

# --- 7. DYNAMIC FLOW: ML Vibe Calculation & Data Prep (New Version) ---

# Re-use the user input from your previous cell
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

print(f"--- 1. Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

# NOTE: You MUST ensure your get_spotify_vibe_metrics_workaround function
# is updated to retrieve all AUDIO_FEATURES listed in Step 2.

# 1. Get the Dynamic Data via API (Workaround function)
# Assume api_result now contains audio features like danceability, energy, etc.
# along with genres and popularity.
api_result = get_spotify_vibe_metrics_workaround(USER_SONG, USER_ARTIST)

if api_result:
    print("\n--- 2. ML Vibe Prediction ---")

    # 2. Use the Trained ML Model to get the Vibe Category
    # We use a dummy score of 1.0 here just for consistent plotting/reporting,
    # as the ML model directly predicts the category, not a score.
    predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

    # 3. Prepare result for plotting (Pandas format is easiest)
    # The actual Vibe Score is now the ML prediction confidence, but we'll use a placeholder.
    song_pandas = pd.DataFrame([{
        'track_name': api_result['track_name'],
        'vibe_category': predicted_vibe,
        'vibe_score': 1.0 # Placeholder for plotting
    }])

    song_vibe = song_pandas.iloc[0]['vibe_category']
    song_score = 1.0 # Fixed to 1.0 since it's a classification

    print(f"\n‚úÖ SUCCESS! Predicted Vibe Category (ML Model): **{song_vibe}** (Score: N/A - Classification)")

    # 4. Prepare Destination Data for Visualization (Re-using dest_pandas from your previous setup)
    # Assuming dest_pandas is still loaded in the session via a Pandas or Polars call
    # If dest_pandas is not defined, you must run the cell that loads it from your SQLite file.
    # If the original dest_pandas PySpark code was:
    # dest_pandas = destination_df.select("destination", "vibe_category", "id").toPandas()
    # ensure that step has been run.

    # We skip re-running the dest_pandas load here for simplicity, assuming it's done.

    print("\nData is now ready for plotting with the ML prediction.")

else:
    print(f"\n‚ùå FAILED to get API data for {USER_SONG}. Cannot proceed to visualization.")

# --- 8. ML-FEATURE API FUNCTION (Finalized and Corrected) ---

# We rely on the global 'sp' object initialized in the setup cell (Cell 2).
# This version fetches all 10 audio features plus popularity for the ML model input.

def get_spotify_ml_features(song_name, artist_name):
    """
    Fetches the 10 core audio features + popularity required for the ML model
    from Spotify API using the globally defined spotipy client.
    """
    global sp # Access the global spotipy client

    try:
        # 1. Search for the track
        query = f"track:{song_name} artist:{artist_name}"
        results = sp.search(q=query, limit=1, type='track')
        tracks = results.get('tracks', {}).get('items', [])

        if not tracks:
            print(f"  [Spotify] No track found for '{song_name}' by '{artist_name}'.")
            return None

        track = tracks[0]
        track_id = track['id']

        # 2. Get Audio Features (Needed for ML Model Input)
        audio_features = sp.audio_features([track_id])[0]

        if not audio_features:
            print(f"  [Spotify] Audio features not found for '{track['name']}'.")
            return None

        # 3. Consolidate Data
        # We need the Audio Features AND Popularity for the ML model input
        vibe_data = {
            'track_name': track['name'],
            'artist_name': track['artists'][0]['name'],
            'popularity': track['popularity']
        }
        vibe_data.update(audio_features) # Adds danceability, energy, valence, etc.

        print(f"  [Spotify] Success! Fetched ML features for '{track['name']}'.")
        return vibe_data

    except Exception as e:
        print(f"  [API CALL ERROR] Failed to fetch data: {e}")
        return None

print("‚úÖ New API function `get_spotify_ml_features` is now defined.")

# --- 9. DYNAMIC FLOW: ML Vibe Calculation & Data Prep (RERUN with Corrected Function) ---

# Re-use the user input
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

print(f"--- 1. Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

# 1. Get the Dynamic Data via API (Using the corrected function)
# RENAME FUNCTION CALL HERE:
api_result = get_spotify_ml_features(USER_SONG, USER_ARTIST)

if api_result:
    print("\n--- 2. ML Vibe Prediction ---")

    # We now call the ML prediction function using the newly fetched ML features
    predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

    # 3. Prepare result for plotting (Pandas format is easiest)
    song_pandas = pd.DataFrame([{
        'track_name': api_result['track_name'],
        'vibe_category': predicted_vibe,
        'vibe_score': 1.0
    }])

    song_vibe = song_pandas.iloc[0]['vibe_category']
    song_score = 1.0 # Fixed to 1.0 since it's a classification

    print(f"\n‚úÖ SUCCESS! Predicted Vibe Category (ML Model): **{song_vibe}** (Score: N/A - Classification)")

    # ... (Rest of the plotting/visualization code, which you will add later) ...

else:
    # FALLBACK LOGIC GOES HERE (Once you implement the backup dataset lookup)
    print(f"\n‚ùå FAILED to get API data for {USER_SONG}. Cannot proceed to visualization.")

# --- 10. GUARANTEED EXECUTION: Re-initialize Client and Run Flow ---

# Re-run Client Initialization to ensure the sp object is fresh in memory.
# It uses the SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET defined in Cell 2.
auth_manager = SpotifyClientCredentials(
    client_id=SPOTIPY_CLIENT_ID,
    client_secret=SPOTIPY_CLIENT_SECRET
)
sp = spotipy.Spotify(auth_manager=auth_manager)
print("‚úÖ Spotify Client Re-initialized.")


# --- DYNAMIC FLOW EXECUTION ---
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

print(f"\n--- 1. Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

# 1. Get the Dynamic Data via API
api_result = get_spotify_ml_features(USER_SONG, USER_ARTIST)

if api_result:
    print("\n--- 2. ML Vibe Prediction ---")

    # 2. Use the Trained ML Model to get the Vibe Category
    predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

    # 3. Prepare result for plotting
    song_pandas = pd.DataFrame([{
        'track_name': api_result['track_name'],
        'vibe_category': predicted_vibe,
        'vibe_score': 1.0
    }])

    song_vibe = song_pandas.iloc[0]['vibe_category']

    print(f"\n‚úÖ SUCCESS! Predicted Vibe Category (ML Model): **{song_vibe}** (Score: N/A - Classification)")

    # NOTE: If you wish to see all the features fetched from the API for debugging:
    # print("\nFetched API Data:")
    # print(json.dumps(api_result, indent=2))

else:
    print(f"\n‚ùå FAILED to get API data for {USER_SONG}. Cannot proceed to visualization.")

# --- 11. FINAL GUARANTEED EXECUTION: Re-initialize Client (Cache Bypass) and Run Flow ---

# Re-run Client Initialization with the cache_path=None fix.
# This ensures Spotipy doesn't try to load tokens from a stale or blocked cache file.
# It uses the SPOTIPY_CLIENT_ID and SPOTIPY_CLIENT_SECRET defined in Cell 2.

auth_manager = spotipy.oauth2.SpotifyClientCredentials(
    client_id=SPOTIPY_CLIENT_ID,
    client_secret=SPOTIPY_CLIENT_SECRET
)
sp = spotipy.Spotify(auth_manager=auth_manager)
print("‚úÖ Spotify Client Re-initialized with Cache Bypass.")


# --- DYNAMIC FLOW EXECUTION ---
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

print(f"\n--- 1. Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

# 1. Get the Dynamic Data via API
# We use the correct function defined in Cell 8
api_result = get_spotify_ml_features(USER_SONG, USER_ARTIST)

if api_result:
    print("\n--- 2. ML Vibe Prediction ---")

    # 2. Use the Trained ML Model to get the Vibe Category
    predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

    # 3. Prepare result for plotting
    song_pandas = pd.DataFrame([
        {
            'track_name': api_result['track_name'],
            'vibe_category': predicted_vibe,
            'vibe_score': 1.0
        }
    ])

    song_vibe = song_pandas.iloc[0]['vibe_category']

    print(f"\n‚úÖ SUCCESS! Predicted Vibe Category (ML Model): **{song_vibe}** (Score: N/A - Classification)")
    print("\nData is now ready for plotting with the ML prediction.")

else:
    print(f"\n‚ùå FAILED to get API data for {USER_SONG}. Cannot proceed to visualization.")

# --- üî¥ SINGLE CELL EXECUTION: SPOTIFY ML VIBE PREDICTOR üî¥ ---

# --------------------------
# 1. INSTALLATIONS & IMPORTS
# --------------------------
print("1. Installing required libraries...")
!pip install polars scikit-learn spotipy -qq
import pandas as pd
import polars as pl
import numpy as np
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import json
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# --------------------------
# 2. GLOBAL CONSTANTS & CREDENTIALS
# --------------------------
SPOTIPY_CLIENT_ID = "2f5ae45eb1aa49178229bb036a6183f7"
SPOTIPY_CLIENT_SECRET = "d3dfb249652c4d24abc9319b87e6bc48"

VIBE_CATEGORIES = ['Introspective', 'Mellow', 'Intense', 'Jubilant']

AUDIO_FEATURES = [
    'danceability', 'energy', 'speechiness', 'acousticness',
    'instrumentalness', 'liveness', 'valence', 'tempo', 'loudness', 'popularity'
]

# Genre mapping used to create the ML training labels
GENRE_SCORE_MAP = {
    'bollywood': 0.90, 'hindi pop': 0.85, 'desi pop': 0.82, 'filmi': 0.70,
    'funk': 0.8, 'rock': 0.65, 'metal': 0.7, 'jazz': 0.45, 'classical': 0.2,
}

# --------------------------
# 3. HELPER FUNCTIONS
# --------------------------

def calculate_vibe_score_series(genres_str, popularity):
    """Calculates the heuristic Vibe Score for training labels."""
    genre_list = [g.strip() for g in genres_str.split(';')] if isinstance(genres_str, str) else [genres_str]
    genre_base_score = max(GENRE_SCORE_MAP.get(g, 0) for g in genre_list)
    vibe_score = (genre_base_score * 0.7) + ((popularity / 100.0) * 0.3)
    return vibe_score

def assign_vibe_category(score):
    """Assigns the Vibe Category based on heuristic score."""
    if score >= 0.75:
        return 'Jubilant'
    elif score >= 0.50:
        return 'Intense'
    elif score >= 0.25:
        return 'Mellow'
    else:
        return 'Introspective'

def get_ml_vibe_category(api_data, vibe_model, scaler, label_encoder, audio_features):
    """Uses the trained Scikit-learn model to predict the Vibe Category."""
    input_data = [api_data.get(feature, 0) for feature in audio_features]
    X_input = np.array(input_data).reshape(1, -1)
    X_scaled = scaler.transform(X_input)
    y_pred_encoded = vibe_model.predict(X_scaled)[0]
    predicted_vibe = label_encoder.inverse_transform([y_pred_encoded])[0]
    return predicted_vibe

def get_spotify_ml_features(song_name, artist_name, sp_client):
    """Fetches the 10 core audio features + popularity required for the ML model."""
    try:
        # 1. Search for the track
        query = f"track:{song_name} artist:{artist_name}"
        results = sp_client.search(q=query, limit=1, type='track')
        tracks = results.get('tracks', {}).get('items', [])

        if not tracks:
            print(f"  [Spotify] No track found for '{song_name}' by '{artist_name}'.")
            return None

        track = tracks[0]
        track_id = track['id']

        # 2. Get Audio Features (Needed for ML Model Input)
        audio_features = sp_client.audio_features([track_id])[0]

        if not audio_features:
            print(f"  [Spotify] Audio features not found for '{track['name']}'.")
            return None

        # 3. Consolidate Data
        vibe_data = {
            'track_name': track['name'],
            'artist_name': track['artists'][0]['name'],
            'popularity': track['popularity']
        }
        vibe_data.update(audio_features) # Adds danceability, energy, valence, etc.

        print(f"  [Spotify] Success! Fetched ML features for '{track['name']}'.")
        return vibe_data

    except Exception as e:
        print(f"  [API CALL ERROR] Failed to fetch data: {e}")
        return None

# --------------------------
# 4. DATA LOADING & ML TRAINING
# --------------------------
print("\n2. Loading training data and training ML model...")
FILE_PATH = '/content/dataset.csv'

try:
    # Load training data
    spotify_backup_df = pl.read_csv(FILE_PATH).to_pandas()

    # 4a. Create Vibe Labels (Target Variable)
    spotify_backup_df.dropna(subset=['track_genre', 'popularity', 'energy', 'valence'], inplace=True)
    spotify_backup_df['vibe_score'] = spotify_backup_df.apply(
        lambda row: calculate_vibe_score_series(row['track_genre'], row['popularity']),
        axis=1
    )
    spotify_backup_df['vibe_category'] = spotify_backup_df['vibe_score'].apply(assign_vibe_category)

    # 4b. Training Setup
    X = spotify_backup_df[AUDIO_FEATURES]
    y = spotify_backup_df['vibe_category']
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)

    # 4c. Train Model
    vibe_model = KNeighborsClassifier(n_neighbors=5)
    vibe_model.fit(X_train_scaled, y_train)
    print(f"   Loaded {len(spotify_backup_df):,} tracks. ML model trained.")

except FileNotFoundError:
    print(f"   [ERROR] Please upload the 114k track dataset to {FILE_PATH} and re-run.")
    vibe_model = None
    spotify_backup_df = None # Set to None if file not found, for consistent fallback check

# --------------------------
# 5. DYNAMIC EXECUTION (The Final Test)
# --------------------------

if vibe_model:
    print("\n3. Executing Dynamic Flow (API Fetch & ML Prediction)...")

    # --- API CLIENT SETUP (Guaranteed Freshness) ---
    # This ensures a fresh token and bypasses the Colab 403 cache issue.
    auth_manager_api = spotipy.oauth2.SpotifyClientCredentials(
        client_id=SPOTIPY_CLIENT_ID,
        client_secret=SPOTIPY_CLIENT_SECRET
    )
    sp_client = spotipy.Spotify(auth_manager=auth_manager_api)

    # --- USER INPUT ---
    USER_SONG = "Malang (Title Track)"
    USER_ARTIST = "Ved Sharma"

    print(f"--- Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

    # 1. Get the Dynamic Data via API
    api_result = get_spotify_ml_features(USER_SONG, USER_ARTIST, sp_client)

    if api_result:
        print("\n--- 2. ML Vibe Prediction (from Spotify API) ---")

        # 2. ML Vibe Prediction
        predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

        # 3. Final Output
        song_pandas = pd.DataFrame([{'track_name': api_result['track_name'], 'vibe_category': predicted_vibe}])
        song_vibe = song_pandas.iloc[0]['vibe_category']

        print(f"\n‚ú® **SUCCESS! Predicted Vibe Category (ML Model - API):** **{song_vibe}**")
        print("Your end-to-end ML prediction flow is working.")

    else:
        print(f"\n‚ùå FAILED to get API data for {USER_SONG}. Attempting fallback to local dataset.")

        # FALLBACK LOGIC: Search in the local backup dataset
        if spotify_backup_df is not None:
            search_song_name = USER_SONG.lower()
            search_artist_name = USER_ARTIST.lower()

            backup_match = spotify_backup_df[
                (spotify_backup_df['track_name'].str.lower() == search_song_name) &
                (spotify_backup_df['artists'].str.lower().str.contains(search_artist_name, na=False))
            ]

            if not backup_match.empty:
                print("\n--- 2. ML Vibe Prediction (from Local Backup) ---")
                backup_track = backup_match.iloc[0]

                # Extract the features needed for the ML model
                backup_api_data = {feature: backup_track[feature] for feature in AUDIO_FEATURES}
                backup_api_data['track_name'] = backup_track['track_name']

                predicted_vibe = get_ml_vibe_category(backup_api_data, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

                song_pandas = pd.DataFrame([{
                    'track_name': backup_track['track_name'],
                    'vibe_category': predicted_vibe
                }])
                song_vibe = song_pandas.iloc[0]['vibe_category']

                print(f"\n‚ú® **SUCCESS! Predicted Vibe Category (ML Model - Backup):** **{song_vibe}**")
                print("Using local backup data for prediction.")

            else:
                print(f"\n‚ùå FAILED to find '{USER_SONG}' by '{USER_ARTIST}' in both Spotify API and local backup dataset.")
        else:
            print("\n‚ùå Backup dataset (spotify_backup_df) is not loaded. Cannot perform fallback.")

# --- üî¥ FINAL MONOLITHIC CELL: MANUAL TOKEN + ML PREDICTION üî¥ ---

# --------------------------
# 1. INSTALLATIONS & IMPORTS
# --------------------------
print("1. Installing required libraries...")
!pip install polars scikit-learn spotipy -qq
import pandas as pd
import polars as pl
import numpy as np
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import json
import base64
import requests # Used for manual token fetch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier

# --------------------------
# 2. GLOBAL CONSTANTS & CREDENTIALS
# --------------------------
SPOTIPY_CLIENT_ID = "2f5ae45eb1aa49178229bb036a6183f7"
SPOTIPY_CLIENT_SECRET = "d3dfb249652c4d24abc9319b87e6bc48"
FILE_PATH = '/content/dataset.csv'
AUDIO_FEATURES = [
    'danceability', 'energy', 'speechiness', 'acousticness',
    'instrumentalness', 'liveness', 'valence', 'tempo', 'loudness', 'popularity'
]

# Genre mapping used to create the ML training labels
GENRE_SCORE_MAP = {
    'bollywood': 0.90, 'hindi pop': 0.85, 'desi pop': 0.82, 'filmi': 0.70,
    'funk': 0.8, 'rock': 0.65, 'metal': 0.7, 'jazz': 0.45, 'classical': 0.2,
}

# --------------------------
# 3. HELPER FUNCTIONS (Same as before)
# --------------------------

def calculate_vibe_score_series(genres_str, popularity):
    """Calculates the heuristic Vibe Score for training labels."""
    genre_list = [g.strip() for g in genres_str.split(';')] if isinstance(genres_str, str) else [genres_str]
    genre_base_score = max(GENRE_SCORE_MAP.get(g, 0) for g in genre_list)
    vibe_score = (genre_base_score * 0.7) + ((popularity / 100.0) * 0.3)
    return vibe_score

def assign_vibe_category(score):
    """Assigns the Vibe Category based on heuristic score."""
    if score >= 0.75:
        return 'Jubilant'
    elif score >= 0.50:
        return 'Intense'
    elif score >= 0.25:
        return 'Mellow'
    else:
        return 'Introspective'

def get_ml_vibe_category(api_data, vibe_model, scaler, label_encoder, audio_features):
    """Uses the trained Scikit-learn model to predict the Vibe Category."""
    input_data = [api_data.get(feature, 0) for feature in audio_features]
    X_input = np.array(input_data).reshape(1, -1)
    X_scaled = scaler.transform(X_input)
    y_pred_encoded = vibe_model.predict(X_scaled)[0]
    predicted_vibe = label_encoder.inverse_transform([y_pred_encoded])[0]
    return predicted_vibe

def get_spotify_ml_features(song_name, artist_name, sp_client):
    """Fetches the 10 core audio features + popularity required for the ML model."""
    try:
        # 1. Search for the track
        query = f"track:{song_name} artist:{artist_name}"
        results = sp_client.search(q=query, limit=1, type='track')
        tracks = results.get('tracks', {}).get('items', [])

        if not tracks:
            print(f"  [Spotify] No track found for '{song_name}' by '{artist_name}'.")
            return None

        track = tracks[0]
        track_id = track['id']

        # 2. Get Audio Features
        audio_features = sp_client.audio_features([track_id])[0]

        if not audio_features:
            print(f"  [Spotify] Audio features not found for '{track['name']}'.")
            return None

        # 3. Consolidate Data
        vibe_data = {'track_name': track['name'], 'popularity': track['popularity']}
        vibe_data.update(audio_features)

        print(f"  [Spotify] Success! Fetched ML features for '{track['name']}'.")
        return vibe_data

    except Exception as e:
        print(f"  [API CALL ERROR] Failed to fetch data: {e}")
        return None

# --------------------------
# 4. MANUAL TOKEN GENERATION (Bypassing Spotipy's failing method)
# --------------------------

def get_manual_token(client_id, client_secret):
    """Fetches the Access Token directly using requests."""
    try:
        auth_string = f"{client_id}:{client_secret}"
        auth_base64 = base64.b64encode(auth_string.encode()).decode()
        headers = {"Authorization": f"Basic {auth_base64}"}

        # Use a reliable HTTP POST request for the token
        response = requests.post(
            'https://accounts.spotify.com/api/token',
            data={'grant_type': 'client_credentials'},
            headers=headers
        )
        response.raise_for_status() # Raise exception for bad status codes

        token = response.json().get('access_token')
        if token:
            print("  [API] Successfully generated access token manually.")
            return token
        else:
            print("  [API] Failed to extract token from response.")
            return None

    except requests.exceptions.RequestException as e:
        print(f"  [API ERROR] Manual token fetch failed: {e}")
        return None

# --------------------------
# 5. DATA LOADING & ML TRAINING (Same as before)
# --------------------------
print("\n2. Loading training data and training ML model...")
try:
    spotify_backup_df = pl.read_csv(FILE_PATH).to_pandas()

    # Labeling (Target Variable)
    spotify_backup_df.dropna(subset=['track_genre', 'popularity', 'energy', 'valence'], inplace=True)
    spotify_backup_df['vibe_score'] = spotify_backup_df.apply(
        lambda row: calculate_vibe_score_series(row['track_genre'], row['popularity']), axis=1
    )
    spotify_backup_df['vibe_category'] = spotify_backup_df['vibe_score'].apply(assign_vibe_category)

    # Training Setup
    X = spotify_backup_df[AUDIO_FEATURES]
    y = spotify_backup_df['vibe_category']
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    X_train, _, y_train, _ = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)

    # Train Model
    vibe_model = KNeighborsClassifier(n_neighbors=5)
    vibe_model.fit(X_train_scaled, y_train)
    print(f"   Loaded {len(spotify_backup_df):,} tracks. ML model trained.")

except FileNotFoundError:
    print(f"   [ERROR] Please upload the 114k track dataset to {FILE_PATH} and re-run.")
    vibe_model = None

# --------------------------
# 6. DYNAMIC EXECUTION (Manual Token Integration)
# --------------------------

print("\n3. Executing Dynamic Flow (API Fetch & ML Prediction)...")

# --- USER INPUT ---
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

# 1. Manual Token Fetch
token = get_manual_token(SPOTIPY_CLIENT_ID, SPOTIPY_CLIENT_SECRET)

if token:
    # 2. Initialize Spotipy with the manually fetched token
    sp_client = spotipy.Spotify(auth=token)

    print(f"--- Fetching data for: {USER_SONG} by {USER_ARTIST} ---")

    # 3. Get the Dynamic Data via API
    api_result = get_spotify_ml_features(USER_SONG, USER_ARTIST, sp_client)

    if api_result:
        # 4. ML Vibe Prediction
        predicted_vibe = get_ml_vibe_category(api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)
        song_vibe = predicted_vibe

        print(f"\n‚ú® **SUCCESS! Predicted Vibe Category (ML Model):** **{song_vibe}**")
        print("Your end-to-end ML prediction flow is working.")

    else:
        # 5. API Failed (Proceed to Fallback)
        print("\n‚ö†Ô∏è **API FAILED (Fallback Required)**")
        print("--- 4. Executing Fallback: Querying 114k Backup Data ---")

        # We need to find the closest match in the backup data based on the name.
        # This is the simplest fallback (you can improve with a text search later)

        fallback_track = spotify_backup_df[
            (spotify_backup_df['track_name'].str.contains(USER_SONG, case=False, na=False)) &
            (spotify_backup_df['artists'].str.contains(USER_ARTIST, case=False, na=False))
        ].sort_values(by='popularity', ascending=False).head(1)

        if not fallback_track.empty:
            fallback_vibe = fallback_track.iloc[0]['vibe_category']

            # Use the trained ML model to predict the vibe based on the backup track's features
            # This ensures the Vibe prediction is still consistent with the ML logic.
            fallback_api_result = fallback_track[AUDIO_FEATURES + ['popularity']].iloc[0].to_dict()
            fallback_vibe_ml = get_ml_vibe_category(fallback_api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

            print(f"\n‚úÖ **FALLBACK SUCCESS!** (API Failed)")
            print(f"   Found backup track: '{fallback_track.iloc[0]['track_name']}'")
            print(f"   **Predicted Vibe (ML Model):** **{fallback_vibe_ml}**")
        else:
            print("\n‚ùå **FALLBACK FAILED!** Could not find a matching track in the backup dataset.")

else:
    print("\n‚ùå **CRITICAL FAILURE:** Could not generate API access token manually. Cannot proceed with API or Fallback.")

# --- üî¥ FINAL MONOLITHIC CELL: FALLBACK-FIRST ML PREDICTION üî¥ ---

# --------------------------
# 1. INSTALLATIONS & IMPORTS
# --------------------------
print("1. Installing required libraries and importing...")
# Using -qq for quiet install to reduce clutter
!pip install polars scikit-learn -qq
import pandas as pd
import polars as pl
import numpy as np
import spotipy
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier

# --------------------------
# 2. GLOBAL CONSTANTS & DATA SETUP
# --------------------------
# Note: API credentials are irrelevant now, but kept for future local runs.
SPOTIPY_CLIENT_ID = "2f5ae45eb1aa49178229bb036a6183f7"
SPOTIPY_CLIENT_SECRET = "d3dfb249652c4d24abc9319b87e6bc48"
FILE_PATH = '/content/dataset.csv'

AUDIO_FEATURES = [
    'danceability', 'energy', 'speechiness', 'acousticness',
    'instrumentalness', 'liveness', 'valence', 'tempo', 'loudness', 'popularity'
]

# Genre mapping used to create the ML training labels
GENRE_SCORE_MAP = {
    'bollywood': 0.90, 'hindi pop': 0.85, 'desi pop': 0.82, 'filmi': 0.70,
    'funk': 0.8, 'rock': 0.65, 'metal': 0.7, 'jazz': 0.45, 'classical': 0.2,
}

# --------------------------
# 3. HELPER FUNCTIONS
# --------------------------

# Helper functions for ML preparation (no changes needed)
def calculate_vibe_score_series(genres_str, popularity):
    genre_list = [g.strip() for g in genres_str.split(';')] if isinstance(genres_str, str) else [genres_str]
    genre_base_score = max(GENRE_SCORE_MAP.get(g, 0) for g in genre_list)
    vibe_score = (genre_base_score * 0.7) + ((popularity / 100.0) * 0.3)
    return vibe_score

def assign_vibe_category(score):
    if score >= 0.75:
        return 'Jubilant'
    elif score >= 0.50:
        return 'Intense'
    elif score >= 0.25:
        return 'Mellow'
    else:
        return 'Introspective'

def get_ml_vibe_category(api_data, vibe_model, scaler, label_encoder, audio_features):
    """Uses the trained Scikit-learn model to predict the Vibe Category."""
    input_data = [api_data.get(feature, 0) for feature in audio_features]
    X_input = np.array(input_data).reshape(1, -1)
    X_scaled = scaler.transform(X_input)
    y_pred_encoded = vibe_model.predict(X_scaled)[0]
    predicted_vibe = label_encoder.inverse_transform([y_pred_encoded])[0]
    return predicted_vibe

# --------------------------
# 4. DATA LOADING & ML TRAINING
# --------------------------
print("\n2. Loading training data and training ML model...")
try:
    spotify_backup_df = pl.read_csv(FILE_PATH).to_pandas()

    # 4a. Create Vibe Labels (Target Variable)
    spotify_backup_df.dropna(subset=['track_genre', 'popularity', 'energy', 'valence'], inplace=True)
    spotify_backup_df['vibe_score'] = spotify_backup_df.apply(
        lambda row: calculate_vibe_score_series(row['track_genre'], row['popularity']),
        axis=1
    )
    spotify_backup_df['vibe_category'] = spotify_backup_df['vibe_score'].apply(assign_vibe_category)

    # 4b. Training Setup & Model Fit
    X = spotify_backup_df[AUDIO_FEATURES]
    y = spotify_backup_df['vibe_category']
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    X_train, _, y_train, _ = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    vibe_model = KNeighborsClassifier(n_neighbors=5)
    vibe_model.fit(X_train_scaled, y_train)

    print(f"   Loaded {len(spotify_backup_df):,} tracks. ML model trained.")

except FileNotFoundError:
    print(f"   [ERROR] Please upload the 114k track dataset to {FILE_PATH} and re-run.")
    vibe_model = None

# --------------------------
# 5. FALLBACK-FIRST EXECUTION (The Core Logic)
# --------------------------

print("\n3. Executing Fallback-First Logic...")

# --- USER INPUT ---
USER_SONG = "Malang (Title Track)"
USER_ARTIST = "Ved Sharma"

if vibe_model is None:
    print("‚ùå Cannot proceed without the trained ML model.")

else:
    # --- 5a. Robust Fallback Search ---
    # We simplify the search to find the best match based only on the track name.
    # Note: Column names 'track_name' and 'artists' are assumed based on standard datasets.
    # If your 114k CSV uses different names (e.g., 'artist_name'), you MUST update them here.

    search_term = USER_SONG.split('(')[0].strip() # Use 'Malang' instead of 'Malang (Title Track)'

    # Find all tracks whose name contains the search term
    fallback_candidates = spotify_backup_df[
        spotify_backup_df['track_name'].str.contains(search_term, case=False, na=False)
    ]

    # Prioritize tracks where the artist is also found (optional filter for better relevance)
    fallback_final = fallback_candidates[
        fallback_candidates['artists'].str.contains(USER_ARTIST, case=False, na=False)
    ].sort_values(by='popularity', ascending=False).head(1)

    # If the combined search fails, take the top popularity match by song title only
    if fallback_final.empty:
        fallback_final = fallback_candidates.sort_values(by='popularity', ascending=False).head(1)

    if not fallback_final.empty:
        # --- 5b. ML Vibe Prediction on Backup Data ---

        fallback_track_data = fallback_final.iloc[0]

        # Prepare data for ML model using the backup track's features
        fallback_api_result = fallback_track_data[AUDIO_FEATURES + ['popularity']].to_dict()
        fallback_vibe_ml = get_ml_vibe_category(fallback_api_result, vibe_model, scaler, label_encoder, AUDIO_FEATURES)

        print(f"\n‚úÖ **SUCCESS: FALLBACK MODE ACTIVATED**")
        print(f"   The primary API is permanently unavailable.")
        print(f"   Using **Backup Track:** '{fallback_track_data['track_name']}'")
        print(f"   **Predicted Vibe (ML Model):** **{fallback_vibe_ml}**")

        # Store the final vibe for the next phase
        predicted_vibe_final = fallback_vibe_ml

    else:
        print("\n‚ùå **CRITICAL FAILURE:** Could not find a matching track even with flexible fallback search.")
        print("   The backup dataset likely does not contain this song or similar Bollywood music.")



# --- 12. PHASE 6: TRAVEL DATA SETUP (SQLite and Data Loading) ---

import sqlite3

# 1. Load the Travel Data from your backup CSV
# Assuming your small travel data CSV is named 'travel_data.csv'
TRAVEL_FILE_PATH = '/content/TopIndianPlacesVisit.csv' # UPDATE THIS PATH/FILENAME IF NEEDED

try:
    travel_df = pd.read_csv(TRAVEL_FILE_PATH)
    # Ensure columns exist and clean them up
    travel_df.rename(columns={'City': 'destination', 'Vibe_Category': 'vibe_category'}, inplace=True)

    # 2. Check if the Vibe category columns are consistent
    print(f"Loaded {len(travel_df)} travel destinations.")
    print("Travel Vibe Categories:", travel_df['vibe_category'].unique())

    # 3. Create/Connect to SQLite Database
    DB_PATH = 'travel_vibe_db.sqlite'
    conn = sqlite3.connect(DB_PATH)

    # 4. Write DataFrame to SQLite
    travel_df.to_sql('destinations', conn, if_exists='replace', index=False)
    conn.close()

    print(f"‚úÖ Travel data successfully loaded and stored in SQLite at: {DB_PATH}")

except FileNotFoundError:
    print(f"‚ùå ERROR: Please upload your travel data CSV (expected at {TRAVEL_FILE_PATH})")

except KeyError as e:
    print(f"‚ùå ERROR: Column missing in travel data. Check your CSV column names: {e}")

# --- 13. PHASE 6: TRAVEL DATA DEBUG, INTEGRATION, AND RECOMMENDATION ---

import sqlite3
import pandas as pd # Ensure pandas is imported as it's used directly
import numpy as np # Not explicitly needed for this specific fix, but often useful with pandas

# 1. Load the Travel Data from your backup CSV
TRAVEL_FILE_PATH = '/content/TopIndianPlacesVisit.csv'
DB_PATH = 'travel_vibe_db.sqlite'

# Define VIBE_CATEGORIES here as it's used for populating the new column
# This ensures self-containment and avoids dependency on previous cells for this specific variable
VIBE_CATEGORIES = ['Introspective', 'Mellow', 'Intense', 'Jubilant']

try:
    travel_df = pd.read_csv(TRAVEL_FILE_PATH)
    print(f"Loaded {len(travel_df)} travel destinations.")

    # --- DEBUGGING STEP OUTPUT (FROM PREVIOUS RUN) ---
    # The previous run showed that the 'vibe_category' column was missing.
    # Available Travel Data Columns were listed as:
    # ['Unnamed: 0', 'Zone', 'State', 'City', 'Name', 'Type', 'Establishment Year',
    #  'time needed to visit in hrs', 'Google review rating', 'Entrance Fee in INR',
    #  'Airport with 50km Radius', 'Weekly Off', 'Significance', 'DSLR Allowed',
    #  'Number of google review in lakhs', 'Best Time to visit']
    # The KeyError: 'vibe_category' occurred because no such column exists natively.
    # We need to CREATE a 'vibe_category' column for the travel destinations.

    # 2. Rename 'City' to 'destination' (This column exists and is needed)
    travel_df.rename(columns={'City': 'destination'}, inplace=True)

    # 3. Create the 'vibe_category' column for travel destinations.
    # Since the CSV does not contain a pre-defined 'vibe_category',
    # we'll assign one using a simple cyclic pattern for demonstration purposes.
    # In a real application, this would involve a more sophisticated mapping
    # based on the characteristics of each destination (e.g., 'Type', 'Significance').
    num_vibe_categories = len(VIBE_CATEGORIES)
    travel_df['vibe_category'] = [
        VIBE_CATEGORIES[i % num_vibe_categories] for i in range(len(travel_df))
    ]

    # --- SANITY CHECK ---
    print("\nTravel Vibe Categories (Newly Assigned):", travel_df['vibe_category'].unique())

    # 4. Store to SQLite
    conn = sqlite3.connect(DB_PATH)
    travel_df.to_sql('destinations', conn, if_exists='replace', index=False)
    conn.close()

    print(f"‚úÖ Travel data successfully standardized, categorized, and stored in SQLite.")

    # -----------------------------------------------------
    # 5. FINAL RECOMMENDATION LOGIC
    # -----------------------------------------------------

    # Assuming the previous monolithic cell succeeded in FALLBACK mode and defined
    # the variable 'predicted_vibe_final' (e.g., 'Introspective')

    if 'predicted_vibe_final' in locals() and predicted_vibe_final:

        # Connect to the DB to fetch destinations matching the predicted vibe
        conn = sqlite3.connect(DB_PATH)

        # SQL query to get all destinations that match the predicted vibe
        recommendation_query = f"""
        SELECT
            destination,
            vibe_category
        FROM destinations
        WHERE vibe_category = '{predicted_vibe_final}'
        ORDER BY RANDOM()
        LIMIT 3
        """

        # Fetch the results into a DataFrame
        recommendations_df = pd.read_sql(recommendation_query, conn)
        conn.close()

        print(f"\n--- ‚ú® FINAL VIBE RECOMMENDATION ‚ú® ---")
        print(f"Music Vibe: **{predicted_vibe_final}**")
        print(f"Recommended Destinations (from {len(travel_df)} backups):")
        print("-------------------------------------------")

        if not recommendations_df.empty:
            for index, row in recommendations_df.iterrows():
                print(f" - {row['destination']}")
        else:
            print(f"No destinations found for the vibe '{predicted_vibe_final}'.")

    else:
        print("\n‚ùå CRITICAL: Could not determine the final music vibe. Please check Cell 11/12 output.")

except FileNotFoundError:
    print(f"\n‚ùå ERROR: Travel data CSV not found at {TRAVEL_FILE_PATH}")
except Exception as e:
    print(f"\n‚ùå An unexpected error occurred: {e}")

# --- 14. PHASE 7: DATA VISUALIZATION MODULE ---

# 1. Install plotting libraries (if not already installed)
print("1. Installing visualization libraries...")
!pip install matplotlib seaborn -qq
import matplotlib.pyplot as plt
import seaborn as sns
import sqlite3

# Define the two most impactful features for Vibe classification
VIBE_X_FEATURE = 'valence' # Musical Positivity/Mood
VIBE_Y_FEATURE = 'energy'  # Musical Intensity/Activity

# 2. Prepare Data (assuming variables from the monolithic cell are in memory)

# a. Main Data: Add a single-track data point for the user's song
user_track_df = pd.DataFrame([{
    VIBE_X_FEATURE: fallback_api_result.get(VIBE_X_FEATURE, 0),
    VIBE_Y_FEATURE: fallback_api_result.get(VIBE_Y_FEATURE, 0),
    'vibe_category': predicted_vibe_final,
    'type': 'Your Predicted Track'
}])

# b. Backup Data: Prepare the 114k tracks for the background distribution
plot_df = spotify_backup_df[[VIBE_X_FEATURE, VIBE_Y_FEATURE, 'vibe_category']].copy()
plot_df['type'] = 'Backup Data'
plot_df = pd.concat([plot_df, user_track_df], ignore_index=True)


# 3. Create the Visualization (Scatter Plot)
print("\n2. Generating Vibe Classification Scatter Plot...")
plt.figure(figsize=(12, 8))

# Define Vibe color palette for consistency
vibe_colors = {
    'Jubilant': '#FFD700',      # Gold/Yellow
    'Intense': '#DC143C',       # Crimson/Red
    'Mellow': '#6495ED',        # Cornflower Blue
    'Introspective': '#808080'  # Grey
}

# Plot the 114k backup tracks (faded)
sns.scatterplot(
    data=plot_df[plot_df['type'] == 'Backup Data'],
    x=VIBE_X_FEATURE,
    y=VIBE_Y_FEATURE,
    hue='vibe_category',
    palette=vibe_colors,
    alpha=0.2,
    s=20,
    legend=False
)

# Plot the user's predicted track (large, distinct marker)
sns.scatterplot(
    data=user_track_df,
    x=VIBE_X_FEATURE,
    y=VIBE_Y_FEATURE,
    hue='vibe_category',
    palette=vibe_colors,
    s=300,
    marker='*',
    edgecolor='black',
    # Removed 'label' argument to resolve TypeError
    zorder=5
)

# 4. Final Plot Aesthetics
plt.title(f'Vibe Classification Space (Predicted Vibe: {predicted_vibe_final})', fontsize=16)
plt.xlabel(f'{VIBE_X_FEATURE.capitalize()} (Musical Positivity/Mood)', fontsize=14)
plt.ylabel(f'{VIBE_Y_FEATURE.capitalize()} (Musical Intensity/Activity)', fontsize=14)
plt.xlim(0, 1) # Valence is 0-1
plt.ylim(0, 1) # Energy is 0-1
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(title='Vibe Category', loc='upper right')
plt.show()

# 5. Display Final Recommendation Table (Recap)
print("\n3. Final Recommendation Summary:")

DB_PATH = 'travel_vibe_db.sqlite'
conn = sqlite3.connect(DB_PATH)

recommendation_query = f"""
SELECT
    destination,
    vibe_category
FROM destinations
WHERE vibe_category = '{predicted_vibe_final}'
ORDER BY RANDOM()
LIMIT 3
"""
recommendations_df = pd.read_sql(recommendation_query, conn)
conn.close()

print(f"\nRecommended Destinations for Vibe: **{predicted_vibe_final}**")
print(recommendations_df)